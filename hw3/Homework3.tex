% ----------------------------------------------------------------
% AMS-LaTeX Paper ************************************************
% **** -----------------------------------------------------------
\documentclass{amsart}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amscd}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{inconsolata}
\usepackage[shortlabels]{enumitem}
\usepackage[noend]{algpseudocode}
% \usepackage{xy}
% ----------------------------------------------------------------
\vfuzz2pt % Don't report over-full v-boxes if over-edge is small
\hfuzz2pt % Don't report over-full h-boxes if over-edge is small
% THEOREMS -------------------------------------------------------
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lemstar}{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{claim}[thm]{Claim}
\newtheorem*{claimstar}{Claim}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{alg}[thm]{Algorithm}
\newtheorem*{algstar}{Algorithm}
\theoremstyle{remark}
\newtheorem{rmk}[thm]{Remark}
\newtheorem*{rmkstar}{Remark}
\numberwithin{equation}{section}
% MATH -----------------------------------------------------------
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\set}[1]{\left\{#1\right\}}

\newcommand{\NN}{\mathbb N}
\newcommand{\ZZ}{\mathbb Z}
\newcommand{\QQ}{\mathbb Q}
\newcommand{\RR}{\mathbb R}
\newcommand{\CC}{\mathbb C}
\newcommand{\isom}{\cong}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\let\null\varnothing

\pagestyle{plain}
% ----------------------------------------------------------------
\begin{document}
\title[]{Algorithms Homework 3}%
\author{Evan Simmons \\
        Dept.\ of Mathematics \& Computer Science \\ University of California Santa Cruz}%
%\date{}
%\dedicatory{}%
%\commby{}%
\renewcommand{\abstractname}{Homework Option}
% ----------------------------------------------------------------
\begin{abstract}
I have chosen the homework heavy option.
\end{abstract}
\maketitle
% ----------------------------------------------------------------
\section{Problem 6}
Given a sequence of words $W = \{w_0,w_1, \ldots , w_n \}$, we want to partition it into a set of lines where the character length of each line including spaces between the words is no more than $L$. Additionally we want each line to come as close to $L$ as possible.

Formally we seek to minimize the squared slack of the lines where slack is defined as:
$$ \sum_{w \in Line} (|w|+1) -1.$$

To keep track of the indices at which we want to insert newlines we will maintain an array of them $K$ where the index in the array represents the index that the subproblem starts at. We do the same for an array $T$ where we store the minimum squared slack for a given prefix of the words of length equal to the index. We initialize both arrays with null values.  \\
\begin{algorithm}
  \Function{OPT}{j}
    \If{T[j]}
      \Return T[j]
    \EndIf

    \If{j=0}
      \Return $slack^2(0,0)$
    \EndIf

    \State {splits \gets []}{}

    \For{k \gets [0..j]}

      \State{ splits.append((k, opt(k) + $slack^2(k+1,j)$)) }
    \EndFor
    \State{B[j], T[j] \gets minsnd(splits)}

    \State {\Return T[j]}
  \EndFunction
\end{algorithm} \\
where $minsnd$ is the element of the list with the smallest second term,
\begin{flalign*}
  &\textbf{function }slack(i,j) =& \\
  &\hspace{.5cm} s \gets ( L - LEN(i,j) - 1) \\
  &\hspace{.5cm} \textbf{if } (s < 0):\ 
  \textbf{return } \infty \\
  &\hspace{.5cm}  \textbf{else}:\ 
  \textbf{return } s
\end{flalign*}
and,
\begin{flalign*}
   \textbf{function } &LEN(i,j) =\ 0\ \text{if i = j = -1}& \\
   &LEN(i,j) =\ |w_i|+1\ \text{if i = j}& \\
   &LEN(i,j) =\ |w_j|+1\ \text{if i = -1}& \\
   & LEN(i,j) = LEN(i, j-1) + LEN(i-1,j) + LEN(i-1,j-1).
\end{flalign*}

Finally we follow our breadcrumbs in $B$ back through our choices for the indices at which to split.

\begin{algorithm}
  \State{OPT(j)}

  \State{k \gets n}

  \State{res \gets []}

  \While{k \neq 0}

    \State{res.append(B[k])}

    \State{k \gets B[k]}
  \EndWhile
  \Return {res}
\end{algorithm}

\proof{(Of Correctness)}
We seek a partitioning of the words so as to minimize the squared slack. We consider all possible (sequential) partitions of the sequence and take the partition which has minimum loss. This is exactly what OPT does with the additional book-keeping of where the splits occur.

Since the subroutine $slack$ is defined just as in the question, it remains only to show that LEN is correct. LEN is simply the sum of number of characters in a line (including spaces). We define LEN recursively so as to enable the use of previously calculated lengths.

Consider an matrix with $i$ rows and $j$ columns. Since $\forall i,j$ $i\leq j$ said matrix is an upper triangular matrix. If the recursion of OPT were unwound, and we computed the requisite tables incrementally, this would be equivalent to filling the aforementioned $i$ by $j$ matrix column by column from left to right. To compute the length of a sequence we can simply restate it in term of what has already been computed (everything above and left.) We find two sequences whose union is equal to the one we seek (left and above.) We sum their lengths, and subtract the elements whose lengths have been double counted (diagonally up and left.) If we are on the diagonal, we clearly need only the length of the i=jth word, and if we are at the top, we simply add the new word. In the base case of no words spanned, we have 0 length.

\claimstar The above algorithm runs in $O(n^2)$ time.
\proof{(Of Complexity)}
Clearly the body of OPT can be run at most $n$ times since we memoize on $j$ and will call OPT with integers between $1$ and $n$. In the body of OPT the for loop will run at most $n$ times. Finally inside the for loop I claim that $slack$ computes in $0(1)$ time. If my claim is correct, OPT will take $O(n^2)$ time.

It remains to show that $slack$ is $O(1)$. Consider the following:

\begin{algorithm}
  \For {k \gets [0..n]}

    OPT(K)
  \EndFor
\end{algorithm}

In each iteration a matrix of values is built where reach row is an $i$ value, and each column is a $j$ value. Each time through the loop we have already computed the values above and left, so in the worst case we need only perform the arithmetic in the last equation for LEN which is $O(1)$

\section{Problem 10}
 
Suppose we have two machines on which we can run a job. We know the compute time availability for each machine over the next $n$ minutes. We want to choose what machine to run the job on for each minute if we can only run the job on one machine at a time. To switch machines, we must take a penalty of one minute before beginning the job on the new machine.

\subsection*{a.}
Consider the case where $A={2,1}$, and $B={1,10}$, the given algorithm will do the following:

\begin{enumerate}[1)]
  \item Take $a_1$ since it is larger than $b_1$.
  \item Take $a_2$ since there is no $b_3$.
\end{enumerate}

The result is $3$ whereas a correct algorithm should have output $11$.

\subsection*{b.}
Propose an algorithm which returns an optimal plan.

\algstar
We maintain a table of optimal moves T where T[A,t] is the tuple $(P,mx)$ where $P$ is the plan at time $t$ if the job is currently on machine A which achieves the maximal compute time $mx$.
\begin{flalign*}
  \textbf{function } & PLAN(P,n) = (P,0) &\\
  & PLAN(P,t) = \\
  &\ \ M \gets P.last() \\
  &\ \ \textbf{if } T[M][t]: \\
  &\ \ \ \ (P+P',mx) \gets T[M][t] \\
  &\ \ \ \ \textbf{return } (P++P', mx) \\
  &\ \ (P_1,mx_1) \gets PLAN((P++[M],t+1) \\
  &\ \ (P_2,mx_2) \gets PLAN((P++[\bar{M}],\bar{M},t+1) \\
  &\ \ \textbf{if } max \{mx_1+M_t, mx_2\} = mx_1: \\
  &\ \ \ \ T[M][t] \gets (P_1, mx_1+M_t) \\
  &\ \ \textbf{else: } \\
  &\ \ \ \ T[M][t] \gets (P_2, mx_2) \\
  &\ \ \textbf{return } T[M][t]\\
\end{flalign*}
where $M$ is the current machine and $\bar{M}$ is the other machine.

To find the optimal plan, we compute:

$$ \text{fst . }maxsnd \{ PLAN([A],A, 2), PLAN([A],B, 2) \} $$

\proof{(Of Correctness)}
In PLAN, we consider all possible compute plan's, we recursively select the plan with maximal yield in the call to $max$ in our function's body. Clearly by selecting the maximum of all possible plans, we will select the optimal one.


\claimstar The given algorithm runs in $O(n)$ time (given a fixed number of machines).
\proof{(Of Complexity)}
Clearly, once we have filled out the table $T$ any new input to PLAN given the same A and B schedule will run in constant time since it will simply be a lookup. Before such a time, consider running PLAN on the tails of increasing size from the given schedules. Since each new plan depends only on the plan for the subsequent sections of the schedule, those directly following it (which have previously been computed), each call to PLAN takes constant time.




\section{Problem 14}
\subsection*{a.}
Consider a sequence of graphs $\{G\}_{i=0}^b$. Suppose for $s,t \in V$ there is at least one $s-t$ path in all graphs. Provide a polynomial-time algorithm to find the shortest such path.
\algstar
We combine all graphs in the sequence into a new graph $H$ defined as:

$$ H = \left( V, \bigcap_{G(V,E) \in \{G\}} E \right). $$

We then run Dijkstra's on this new graph, and we have our result.

\proof
The proof follows directly from the definition of the intersection. The minimum path over all graphs in the sequence is that for which all its edges are in all graph, and of the $s-t$ paths remaining is the shortest.

Clearly this takes $O(mlog(n)+b)$ time, $b$ to combine the graphs, and $mlog(n)$ to run Dijkstra's on the result.

\subsection*{b.}
Give a polynomial-time algorithm to find a sequence of $s-t$ paths of minimum cost. We first let:

$$ H_{ij} = \left( V, \bigcap_{G(V,E) \in \{G\}_{i}^j} E \right). $$

Then we compute PATH(b) and maintain an array $P$ and $C$ which for a given index we store the path taken in $P$ and in $C$we store the minimum loss possible after making such a choice. For instance if the second clause of PATHS is minimum, we record P[i..j] as the MCP chosen.
\algstar
\begin{align*}
  & PATHS(-1) = -k \\
  & PATHS(0) = MCP(G_0) \\
  & PATHS(j) = \min_{0 \leq i \leq j} \left\{ MCP(H_{ij}) \cdot (j-i+1) + PATHS(i-1) + k) \right\} \\
\end{align*}

where MCP is the minimum cost $s-t$ path (which should be implemented using memoization). (We may simply use Dijkstra's Algorithm.)

\proof{ (Of Correctness) }
In PATHS we are considering the prefixes of the sequence of graphs, and attempting to produce a minimum cost path sequence defined by:
$$\# Path\ switchings + \sum_{P \in Paths} cost(P)$$

Suppose PATH(i-1) returns the correct loss, then if we take the minimum cost first split among all $i$'s we have found the minimum cost splitting. In accordance with the above loss function we need to correctly compute the minimum cost path for a given splitting. Certainly by finding the $H_{ij}$ graph which contains only common edges among the $ij$ subsequence of graphs, and computing its minimum cost path we have found such a path for the splitting.

\claimstar The given algorithm runs in polynomial time.
\proof{ (Of complexity) }
Consider building a table of the memoized results for MCP. Since there are two arguments passed ($i$ and $j$) the table $i$by $j$. Note that the table is really only half filled since $i \leq j$). Since the indices are at  most $b$, building the table is $O(b^2)$. Now we can lookup the results of MCP in constant time. Consider looping through PATH with $j$ increasing. We call PATH $j$ times. Since the prior results of prior PATH calls ($i-1$) and MCP are memoized, they run in constant time. The loop in the body of PATH runs at most $j$ times, hence PATH is $O(b^2)$ given the that the values for MCP is pre-computed. Therefore our algorithm runs in $O(b^2 + b^2)$ = $O(b^2)$.

\section{Problem 20.}

We want to find the optimal allocation of $H$ hours among $n$ projects where $f_i$ is a non-decreasing function which given the hours of work as input returns the grade received for the indexed project.

We will maintain two $n$ by $H$ tables, the first of which we will use to memoize ALLOC , and a second which stores the minimizing $k$ hours for the $j$th project (Let us call it $K$).
\algstar
\begin{align*}
  & ALLOC(0,\_) = 0 \\ 
  & ALLOC(\_,0) = 0 \\
  & ALLOC(j,h) =
    \max_{0<k<h} \{ ALLOC(j-1, h-k) + f_j(k) \} 
\end{align*}

\proof{ (Of Correctness) }
Clearly if there are zero projects or zero hours, there is zero grade points available. Otherwise we consider all allocations of hours available for a specific job, we find the maximum allocation payoff in terms of the remaining subproblem maximum payoff plus the payoff for the current project. By definition then we have then maximized the possible payoff and in doing so determined the required allocations by storing them in the table. To enumerate the allocations we simply jump back through the filled table: \\


\begin{algorithm}
  \State{j \gets n}

  \State{h \gets H}

  \State{res \gets []}

  \While{j \neq 0}

    \State{k \gets K[j][h]}

    \State{res.push(k)}

    \State{j \gets j-1}

    \State{h \gets h-k}

  \EndWhile\\
  \Return {res}
\end{algorithm}

\claimstar The given algorithm runs in $O(nH^2)$.
\proof{ (Of Complexity) }
The unmemoized body of ALLOC will be called at most $n*H$ times to fill the table. In the body there is a loop which has at most length $H$. Therefore ALLOC operates in $O(nH^2)$. To unwind the resulting table, we require $O(nH)$ time. Since we run them sequentially, we see an overall complexity of $O(nH^2)$.

\

\section{Problem 26.}
We seek to purchase product in an optimal fashion such that we minimize our cost. We pay a flat rate of $K$ to place an order. We pay $c$ per item to store it for a month. We may store at most $s$ items. Finally we know the number of sales that will be made for the next $n$ months. Let $d_i$ denote the number of items sold in month $i$. $D$ is a sequence of $d_i$'s which denotes the purchases for all $n$ months.

We memoize PURCH using an array to store the return value for an input month index. For the minimizing $i$ we store it in a table $T$ indexed by $j$ (the size of the sub-problem).
\algstar
\begin{align*}
  & PURCH(0) = 0 \\ 
  & PURCH(j) =
    \min_{0<i \leq j} \{ COST(i,j) + K + PURCH(i-1) \} 
\end{align*}

where:

\begin{align*}
  COST(i,j) = 
    \begin{cases}
      \displaystyle\sum_{l=i}^j d_l [c(l-i)] & \mbox{if } \displaystyle\sum_{l=i}^j d_k \leq s \\
      \infty & \mbox{o.w.}
    \end{cases}
\end{align*}

\proof{ (Of Correctness) }
By virtue of the fact that $K$ is a flat rate, it never makes sense to store only some of the trucks required in a given month. Therefore we can simplify the problem to the question of for what months do we place an order for all trucks required until the next order. Clearly if there are no more months to consider, we need not make a purchase or store trucks. Otherwise we find the month to make a purchase for which the sum of the cost to store the trucks until the given month and the cost of making the purchase and the cost of the resulting subproblem is least.

\claimstar The given algorithm runs in cubic time.
\proof{ (Of Complexity) }
To fill the memoization table for PURCH we compute the body of PURCH at most $n$ times. In the body we have a loop which has at most $n$ steps. Finally in each step of the loop, there are at most $n$ additions to make for a call to COST. Hence we have cubic time.

\rmkstar We could have used a similar technique as in Problem 6 to make the computation of COST only take constant time.

We would simply memoize COST, memoize the threshold for comparing with $s$ and let:
$$ COST(i,j) = COST(i-1,j + COST(i,j-1) + COST(i-1,j-1) \text{ if } \leq s. $$



\section{Bonus: Problem 19.}

Given two sequences $x$ and $y$ we seek to determine if $s$ is an interleaving of $x$ and $y$.

Below we will call $k_x$ and $k_y$ the indices which point to an element of $x^\infty$ and $y^\infty$. We will memoize IL using a $k_x$ by $k_y$ table called $K$.
\algstar
\begin{align*}
  & IL(k_x,k_y) =
  \begin{cases}
    k_x + k_y = |s| &\Rightarrow True \\
    match(k_x,k_y) = \{x,y\} & \Rightarrow IL(k_x+1, k_y)\ \vee\ IL(k_x, k_y+1) \\
    match(k_x,k_y) = \{x\} &\Rightarrow IL(k_x+1, k_y) \\
    match(k_x,k_y) = \{y\} &\Rightarrow IL(k_x, k_x+1) \\
    match(k_x,k_y) = \null &\Rightarrow False \\
  \end{cases} \\
\end{align*}
 where the definition of match below simply returns the matching signals (a subset of \{x,y\}.)

\begin{flalign*}
  match(k_x, k_y) =& \{\mbox{if } x^\infty [k_x] == s[k_x+k_y-1] \Rightarrow x \}& \\
   \cup &\{ \mbox{if } y^\infty [k_y] == s[k_x+k_y-1] \Rightarrow y \}
\end{flalign*}

\proof{ (Of Correctness) }
Trivially the empty sequence is an interleaving of any two sequences. We proceed via case analysis for each element of $s$. An element either matches $x$, $y$, $x$ and $y$, or neither. In the first, the correct action is to attempt to match the rest of $s$ with the rest of $x^\infty$ and an unchanged $y^\infty$. In the second, we proceed similarly to the first. In the third, we say that it is an interleaving if either matches, and return the conjunction of the first two cases. Finally in the fourth clearly we do not have an interleaving.

\proof{ (Of Complexity) }
Since IL is memoized, it computes a table which is potentially as large as $s$ by $s$ Each time it is called, we do constant work in $match$. Therefore we will do $O(s^2)$ work.

\section{Bonus of Bonuses?}
You are having a cocktail party, and want to buy ingredients for drinks. You want to balance the number of ingredients you buy (and therefore, the money you spend) with the variety of drinks at the party.
 
Let $I$ be the set of all possible cocktail ingredients, and $R$ be the set of all cocktail recipes you know, where each $r$ in $R$ is a nonempty set comprised of elements in $I$. Let $available(K,R)$, where $K$ is a set of ingredients in $I$, represent the number of recipes in $R$ whose ingredients are all included in $K$. Find the set of ingredients $I'$ such that $available(I',R)$ / $size(I')$ is maximized. \\

We memoize the algorithm below with a table $TR$ with the result and $TI$ of the ingredients that produced it, both indexed by $j$.
\begin{algorithm}
  \Function{ING}{j}

    \State{P \gets \mathbb{P}(I)}

    \State{I' \gets \max \{available(I',R) : |I'| = j, I' \in P\}}

    \Return{I'}

  \EndFunction
\end{algorithm}

Now we simply find the index $j$ for which $\frac{TR[j]}{j}$ is maximized, we return $TI[j]$ (the ingredients list from the built table.)

\proof{ (Of complexity) }
For a given $R$ we compute ING at most $j$ times. In ING we consider at most $2^I$ sets of ingredients. The performance is therefore unacceptable.

After considering this results for some time I realized that the subproblems had to be in terms of $I'$ to apply dynamic programming.



\end{document}
